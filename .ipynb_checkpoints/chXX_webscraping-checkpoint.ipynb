{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7d3bbf-f487-4b33-84e5-9206254d500f",
   "metadata": {},
   "source": [
    "# Teil XY: Webscraping\n",
    "Mit `requests` k칬nnen wir bereits auf Internetressourcen zugreifen, darunter APIs mit strukturierten Daten. Der Gro릆eil des Internets besteht allerdings aus Webseiten, die f칲r Menschen und nicht Maschinen gemacht sind. Um sie in Python zu verarbeiten, ben칬tigen wir neue Tools und ein Grundverst칛ndnis der zugrundeliegenden Technologie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48179f-6fc6-4bff-a156-452582744739",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## X.0 Die Auszeichnungssprache HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c3b6f-26a3-4209-8977-fcd0178cbb62",
   "metadata": {},
   "source": [
    "Webseiten bestehen nicht nur aus Text - praktisch jede Seite besitzt 칖berschriften, Bilder, Links und viele andere **Strukturelemente**. Die [Hypertext Markup Language (HTML)](https://de.wikipedia.org/wiki/Hypertext_Markup_Language) ist die Standardsprache, um diese Elemente zu definieren. Daf칲r werden **Tags** genutzt, die entweder f칲r sich stehen oder als eine Art Klammer vor und nach einen Text stehen.\n",
    "\n",
    "Nebenbemerkung: Die **visuelle Darstellung** einer Webseite wird getrennt davon mit [Cascading Style Sheets (CSS)](https://de.wikipedia.org/wiki/Cascading_Style_Sheets) festgelegt, die uns gl칲cklicherweise hier nicht interessieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef796f-e4a9-4985-b9da-ad08f1cd10e9",
   "metadata": {},
   "source": [
    "### 칖berschriften, Bl칬cke, Abs칛tze, Links und Bilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0fb98-2d70-4c44-a15c-858d267240f1",
   "metadata": {},
   "source": [
    "Die wichtigsten HTML-Elemente f칲r unsere Zwecke sind:\n",
    "- 칖berschriften, markiert durch das Tag-Paar `<h1>` und `</h1>` bzw. `<h2>`, `<h3>`, `<h4>`, `<h5>` und `<h6>`.\n",
    "- Bl칬cke, markiert durch das Tag-Paar `<div>` und `</div>`.\n",
    "- Abs칛tze, markiert durch das Tag-Paar `<p>` und `</p>`.\n",
    "- Links, markiert durch das Tag-Paar `<a>` und `</a>`.\n",
    "- Bilder, markiert durch den alleinstehenden Tag `<img>`.\n",
    "\n",
    "Am Rande sei au른rdem auf `<ul>`, `<ol>` und `<li>` f칲r Listen verwiesen (s. https://www.w3schools.com/html/html_lists.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dbc71-d6a5-4443-b5f3-e9854284bf09",
   "metadata": {},
   "source": [
    "### 游빍Experiment: HTML ver칛ndern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acfe61c-fb9a-4445-beb4-220328e6536a",
   "metadata": {},
   "source": [
    "Der folgende HTML-Code definiert eine einfache Webseite, die darunter abgebildet ist.\n",
    "\n",
    "```html\n",
    "<h3>Meine Webseite</h3>\n",
    "<img src=\"https://cdn.pixabay.com/photo/2016/05/08/14/58/icon-1379228_1280.png\" width=\"200em\">\n",
    "<div>\n",
    "    <p>Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.</p>\n",
    "    <p>At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.</p>\n",
    "</div>\n",
    "<h4>Was hei릆 das?</h4>\n",
    "<div>\n",
    "    <p>Vielleicht fragst du dich, was die einleitenden Abs칛tze bedeuten. Die Antwort ist: Nichts! Es handelt sich um <a href=\"https://de.wikipedia.org/wiki/Lorem_ipsum\">Lorem Ipsum</a>, einen klassischen Platzhaltertext.</p>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde8ac3-0d15-4fa6-95a4-2445266c857b",
   "metadata": {},
   "source": [
    "Mit einem **Doppel-Klick auf das untenstehende Textfeld** kannst du den zugrundeliegenden HTML-Code einsehen und bearbeiten. 츿ndere ihn ein wenig ab und sie dir das Ergebnis an. Versuche, die **Reihenfolge der 칖berschriften** zu 칛ndern, **Tags** zu entfernen und einen **neuen Link** zu einer anderen Webseite einzuf칲gen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483db17e-f8b0-4395-acb4-f46fa0a0d6d2",
   "metadata": {},
   "source": [
    "<h1>Meine Webseite</h1>\n",
    "<img src=\"https://cdn.pixabay.com/photo/2016/05/08/14/58/icon-1379228_1280.png\" width=\"200em\">\n",
    "<div>\n",
    "    <p>Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.</p>\n",
    "    <p>At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.</p>\n",
    "</div>\n",
    "<h2>Was hei릆 das?</h2>\n",
    "<div>\n",
    "    <p>Vielleicht fragst du dich, was die einleitenden Abs칛tze bedeuten. Die Antwort ist: Nichts! Es handelt sich um <a href=\"https://de.wikipedia.org/wiki/Lorem_ipsum\">Lorem Ipsum</a>, einen klassischen Platzhaltertext.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a4c0d-fc5b-42f4-aecb-817441024e7a",
   "metadata": {},
   "source": [
    "### Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5a4b5-067e-4095-87d7-11374be5dfaa",
   "metadata": {},
   "source": [
    "Im vorherigen Beispiel sind bereits zwei **Attribute** aufgetaucht: \n",
    "- `href`, um die Adresse eines Links zu definieren\n",
    "- `src`, um den Speicherort einer Bilddatei zu benennen.\n",
    "\n",
    "Ein Attribut steht innerhalb eines Tags direkt nach dem Elementnamen, getrennt durch ein Leerzeichen. Wie **Schl칲sselwortparameter** in Python besteht das Attribut aus dem Namen des Attributs, einem `=` und dem Wert des Attributs:\n",
    "```html\n",
    "<ELEMENT ATTRIBUT=WERT>...</ELEMENT>\n",
    "```\n",
    "\n",
    "Ein Element kann auch mehrere Attribute besitzen, die mit Leerzeichen getrennt werden:\n",
    "```html\n",
    "<ELEMENT ATTRIBUT1=X ATTRIBUT2=Y ATTRIBUT3=Z>...</ELEMENT>\n",
    "```\n",
    "\n",
    "F칲r unsere Zwecke sind zwei Attribute besonders wichtig: `class` und `id`. Eine Klasse ist meist mehreren Elementen zugeordnet, um die Elemente als zusammengeh칬rig zu markieren. IDs  zeichnen hingegen ein bestimmtes Element aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2f6d9-2952-4ec5-b9a4-842d62b27b91",
   "metadata": {},
   "source": [
    "### 游빍Experiment: HTML-Klassen\n",
    "F칲ge dem untenstehenden `<div>`-Tag das `class`-Attribut hinzu und setze seinen Wert auf einen beliebigen String. Setze ihn anschlie른nd auf \"jp-Collapse-header\". Hast du eine Vermutung, was passiert?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8cdfb-5198-40ab-8f1b-8e3d4fd5480d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div>\n",
    "    Doppel-Klick hier!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e4368-7c5a-42cf-88e3-7888b0959c25",
   "metadata": {},
   "source": [
    "### Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f5d3c-75c4-4282-a5fb-41e2e67b242c",
   "metadata": {},
   "source": [
    "F칲r Webscraping mit Pyhton sollten wir folgende Dinge 칲ber HTML wissen:\n",
    "- Eine Webseite besteht aus **Elementen** wie 칖berschriften, Bl칬cken und Links.\n",
    "- Diese Elemente werden mit **Tags** gekennzeichnet, z.B. `<p>...</p>`.\n",
    "- Elemente k칬nnen **Attribute** enthalten, z.B. `href` f칲r Linkadressen.\n",
    "- Elemente k칬nnen **Klassen** und **IDs** besitzen, mit denen sie maschinell identifiziert werden k칬nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b4bf0-126b-4e42-b198-382d67fd0631",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Webseiten finden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d874b-824c-438b-ba24-c4a4fa205e08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Im Verlauf dieses Kapitels werden wir einen Crawler entwickeln, der die Webseiten des LehrLernZentrums verarbeitet, um **alle Seminare f칲r Studierende chronologisch aufzulisten**.\n",
    "\n",
    "Der erste Schritt besteht darin, die Webseite mit Hinblick auf unser Ziel zu analysieren: https://www.hs-rm.de/lehrlernzentrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94775d5-11b0-4f3c-8648-772517c73bab",
   "metadata": {},
   "source": [
    "### 游멆잺칖bung: Relevante Seiten finden\n",
    "Durchsuche die Webseiten des LLZ. Welche Unterseite(n) sind vielversprechend, um die ben칬tigten Informationen zu erhalten?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc5cc3ac-e919-4afa-a759-692519687b28",
   "metadata": {},
   "source": [
    "# Platz f칲r URLs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc582c1-4bd4-4af0-821c-024d040ce757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Webseiten untersuchen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c9483-c6e9-4fac-9bfb-cdebfcfa5bd9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die meisten Webbrowser (Chrome, Firefox, etc.) stellen **Entwicklertools** zur Verf칲gung, mit denen wir den HTML-Code einer Seite analysieren k칬nnen. Meist reicht ein **Rechtsklick** und dann die Option **Untersuchen** bzw. **Inspect**. Es sollte sich dann eine Seitenleiste 칬ffnen, bei der ggf. noch der Tab **Elemente** oder **Inspektor** ausgew칛hlt werden muss.\n",
    "\n",
    "In dieser Ansicht k칬nnen wir uns den HTML-Code neben der gerenderten Webseite anschauen und so die Elemente identifizieren, die uns interessieren. Dabei ist es n칲tzlich, besonders auf **Klassen**, **IDs** und **Element-Verschachtelungen** zu achten: Diese werden es uns sp칛ter erlauben, gezielt auf bestimmte Informationen zuzugreifen.\n",
    "\n",
    "Wir schauen uns das zusammen an der LLZ-Webseite an: https://www.hs-rm.de/lehrlernzentrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3311b05-b938-414c-a9d5-cee4d246958d",
   "metadata": {},
   "source": [
    "### 游멆잺칖bung: Elemente identifizieren\n",
    "Nutze Entwicklertools, um die folgende Seite zu analysieren: https://www.hs-rm.de/lehrlernzentrum/fuer-studierende/studierende-angebote-von-a-bis-z  \n",
    "\n",
    "Wie k칬nnte es gelingen, genau die Links zu identifizieren, die auf Seminare verweisen?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "284288ff-dc58-43cc-b540-efc2a8bc7fcd",
   "metadata": {},
   "source": [
    "# Platz f칲r Ideen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b950-ebb9-4c76-a0df-0f0be378aa04",
   "metadata": {},
   "source": [
    "## 3. Webseiten verarbeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba005c-e705-4faf-8e84-7c94f2ab65f2",
   "metadata": {},
   "source": [
    "Nachdem wir eine Webseite mit `requests` heruntergeladen haben, werden wir die Bibliothek [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) bzw. `bs4` verwenden, um das HTML-Dokument zu **parsen**, d.h. anhand der Struktur die f칲r uns relevanten Informationen zu extrahieren.\n",
    "\n",
    "Der erste Schritt ist das Importieren der Bibliotheken (die leicht unterschiedliche Syntax h칛ngt mit der objektorientierten Natur von Beautiful Soup zusammen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df478629-7afe-498f-a8c5-9f73d7152813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd28335-6c65-46d4-a993-f5c787ce2c65",
   "metadata": {},
   "source": [
    "### Einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcc211-6c10-4369-90ae-eeb1ba8ef503",
   "metadata": {},
   "source": [
    "Wie zuvor laden wir die Webseite mit `requests` herunter und speichern sie als String ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c28d1-8ba5-4855-970e-6e765854396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.hs-rm.de/lehrlernzentrum/fuer-studierende/studierende-angebote-von-a-bis-z')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680739b-2ac6-4ca4-bc32-448afca71da2",
   "metadata": {},
   "source": [
    "Mit dem `BeautifulSoup()`-Befehl k칬nnen wir den HTML-String einlesen. Wir erhalten ein **Objekt**, das viele n칲tzliche Methoden besitzt, um die Seite 칲bersichtlicher darzustellen und bestimmte Elemente zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4ec30-e0e8-4d31-af3d-b03c042f14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9ea26-5190-4f87-803a-27bfc13bf3f3",
   "metadata": {},
   "source": [
    "Die `prettify()`-Methode stellt die Seite 칛hnlich wie die Entwicklertools dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39e0e4-2623-4988-b23a-a4a0c9e1948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e2476-8146-4987-a3fa-0a620161ed54",
   "metadata": {},
   "source": [
    "### Durchsuchen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6236bb-b580-4814-8db2-c43490247907",
   "metadata": {},
   "source": [
    "*Beautiful Soup* stellt uns zwei intuitive, m칛chtige Suchfunktionen zur Verf칲gung:\n",
    "- `find` liefert das erste HTML-Element mit bestimmten Kriterien\n",
    "- `find_all` liefert alle HTML-Elemente mit bestimmten Kriterien\n",
    "\n",
    "\n",
    "Die **Suchkriterien** werden 칲ber die **Funktionsparameter** bestimmt (wir beschr칛nken uns auf die drei grundlegenden, [es gibt aber noch mehr](https://beautiful-soup-4.readthedocs.io/en/latest/#kinds-of-filters):\n",
    "```python\n",
    "soup.find('TAG', ATTRIBUT='WERT', string='TEXT')\n",
    "```\n",
    "Wir gehen sie Schritt f칲r Schritt an Beispielen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b96796-c006-403c-8325-ae19ab46104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finde den ersten <a>-Tag\n",
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb322a-0399-45ec-9834-06bcb14cdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finde das erste Element mit der id 'c54658'\n",
    "soup.find(id='c54658')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b955e09-ff0d-4941-943b-335bc3b857c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finde den ersten <h2>-Tag, in dem der String \"LLZ\" vorkommt\n",
    "import re\n",
    "soup.find('h2', string=re.compile('LLZ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e019c-18c4-45e5-81a3-0f76f9c863cc",
   "metadata": {},
   "source": [
    "### 游멆잺칖bung: Elemente finden\n",
    "Nutze die `soup.find_all()`-Methode, um alle `<a>`-Elemente auszugeben, in denen der String \"Seminar\" enthalten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16bc8076-2fb7-4566-857c-90df4082b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz f칲r die Aufgabe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f31fc9-0355-437f-bf51-f0ab8b19e84d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Auf Inhalt und Attribute zugreifen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32443806-f961-4bb9-9145-89f0ec76bbfd",
   "metadata": {},
   "source": [
    "Nachdem wir die Elemente gefunden haben, die uns interessieren, k칬nnen wir auf ihren **Inhalt** - also den Text, der auf der Webseite zu sehen ist - zugreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf2ef38f-009c-4f62-922e-33b7bd89476e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\tLehrLernZentrum (LLZ)\\n\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sichtbarer Text der ersten h1-칖berschrift\n",
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d406ac-8a77-457a-9e5e-17436653d3ea",
   "metadata": {},
   "source": [
    "Wie im Beispiel zu sehen ist, kann Webseiten-Text manchmal seltsam formatiert sein. Mit der String-Methode `strip()` lassen sich unn칬tige Leerzeichen, Tabs und Zeilenumbr칲che leicht entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5b5dd38-1010-4068-ab1a-68d6a77c3955",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LehrLernZentrum (LLZ)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sichtbarer Text der ersten h1-칖berschrift, ohne Leerzeichen\n",
    "soup.find('h1').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195ae39-3bfc-45ea-ab9b-76b6eb6bd052",
   "metadata": {},
   "source": [
    "Oft interessieren uns aber gar nicht die Texte, sondern bestimmte **Attribute** der Elemente. Auf diese k칬nnen wir wie in einem Dictionary zugreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f4e9e1f-598f-467b-89e3-9dcab9037b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1920'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wert des 'width' Attributs des ersten Bilds\n",
    "soup.find('img')['width']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69a3392-0b1c-4c28-99c2-258ae81b0928",
   "metadata": {},
   "source": [
    "### 游멆잺칖bung: URLs scrapen\n",
    "Nutze die `soup.find_all()`-Methode, um alle `<a>`-Elemente zu finden und gehe sie mit einer `for`-Schleife durch. Falls in ihnen der String \"Seminar\" enthalten ist, gebe die URL in folgendem Format aus:\n",
    "```\n",
    "- [NAME DES SEMINARS]: [URL]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8063e7ee-d0b5-45ab-9922-9a4ff4e0704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz f칲r die 칖bung\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a2123-20b5-4029-8d50-0b0b90d065e6",
   "metadata": {},
   "source": [
    "## 4. Webseiten *crawlen*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5ee00-2c83-4191-82c6-090c2a8c80f9",
   "metadata": {},
   "source": [
    "Wir haben jetzt alle notwendigen Tools, um einen **Crawler** zu entwickeln, der iterativ Seiten abruft und verarbeitet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d65c7ee-b7f7-41b4-b580-bacb58be3d59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Scraping-Ethik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5e8bc-92f4-4b10-b721-8bef6b79f2ca",
   "metadata": {},
   "source": [
    "Webscraping ist zwar n칲tzlich, aber **ethisch teils fragw칲rdig**. Webseiten, die hochwertige Daten bereitstellen, sind f칲r ihre Existenz oft auf auf menschliche Besuche oder kostenpflichtige APIs angewiesen und **verbieten entsprechend das Scraping** ihrer Inhalte. Wiederum andere Webseiten erlauben es grunds칛tzlich, bitten aber um eine kurze Wartezeit zwischen Anfragen, um die Server nicht zu 칲berlasten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5845d5-923f-4c68-b8b6-fd0570b5f85f",
   "metadata": {},
   "source": [
    "### Regeln in `robots.txt` beachten\n",
    "Welche Regeln f칲r eine Webseite gelten, steht meist in der `robots.txt`-Datei, die auf der obersten Ebene der Webseite zu finden ist. Hier ist z.B. der Inhalt von https://www.hs-rm.de/robots.txt:\n",
    "```\n",
    "Sitemap: https:///www.hs-rm.de/sitemap.xml\n",
    "User-agent: *\n",
    "Allow: /\n",
    "Disallow: /typo3/\n",
    "```\n",
    "Diese Anweisung ist sehr liberal: Sie erlaubt jegliche Nutzung, mit der Ausnahme von Seiten unter dem 'typo3'-Verzeichnis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e0a5e-a243-4c84-8e77-3344fa54f956",
   "metadata": {},
   "source": [
    "### 游빍Experiment: robots.txt\n",
    "Schaue dir die `robots.txt`-Datei von www.zeit.de an. F칲ge daf칲r '/robots.txt' ans Ende der URL an und 칬ffne die Seite in einem Browser. Wie interpretierst du die Inhalte der Datei?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7d1b8f-c888-4a50-9509-1119304b6227",
   "metadata": {},
   "source": [
    "# Platz f칲r Notizen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05251319-be58-488a-91d9-38a8a90bf1d2",
   "metadata": {},
   "source": [
    "### Wartezeiten implementieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cebef68-9669-4501-aba3-e21f4dda26bd",
   "metadata": {},
   "source": [
    "Ein bekannter Cyberangriff ist der sog. [DoS-Angriff](https://de.wikipedia.org/wiki/Denial_of_Service), der in einfachster Form einen Server 칲berlastet, indem in sehr kurzer Zeit sehr viele Anfragen gesendet werden. **Verwantwortungsloses Webscraping kann einen 칛hnlichen Effekt haben** - so berichtete etwa Wikipedia Anfang 2025 davon, dass [65% der ressourcenintensivsten Anfragen von Crawlern](https://diff.wikimedia.org/2025/04/01/how-crawlers-impact-the-operations-of-the-wikimedia-projects/) stammen.\n",
    "\n",
    "Eine einfache M칬glichkeit, um Server칲berlastung zu vermeiden, ist das Einbauen von Wartezeiten zwischen Anfragen mit Pythons `time.sleep`-Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6c36c63-d5a1-4f93-9286-d4395cba4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Wartezeit...\n",
      "Wartezeit beendet\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starte Wartezeit...\")\n",
    "time.sleep(5)\n",
    "print(\"Wartezeit beendet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adbed6-8b41-40a8-80ba-734f90648c6e",
   "metadata": {},
   "source": [
    "### 游멆잺칖bung: Zwischen requests warten\n",
    "Rufe mit einer `for`-Schleife f칲nf mal die Seite www.example.com auf, aber warte zwischendurch jeweils eine Sekunde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d67c19-26bc-41c2-bf75-29fd2383c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz f칲r die Aufgabe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34defbd-6815-4888-9b1e-6a3a5133d267",
   "metadata": {},
   "source": [
    "### Sparsam scrapen\n",
    "Zu guter Letzt sind hier noch ein paar allgemeine Hinweise zum Webscraping:\n",
    "- Rufe Webseiten nur einmal mit `requests.get()` auf und speichere das Ergebnis in einer Variable, statt die Seite mehrmals anzufragen.\n",
    "- Vermeide Webscraping g칛nzlich, wenn APIs als Alternative zur Verf칲gung stehen.\n",
    "- Falls eine Webseite den Aufruf mit `requests.get()` blockiert (z.B. wenn ein 403-Fehler zur칲ckkommt), ist das ein recht sicherer Hinweis darauf, dass die Seite das Scraping verbietet.\n",
    "- Lese im Zweifelsfall die Nutzungsbedingungen der Webseite, um zu erfahren, ob und unter welchen Bedingungen Scraping erlaubt ist.\n",
    "- Selbst wenn Scraping erlaubt ist, sind die Inhalte der meisten Webseiten urheber- und datenschutzrechtlich gesch칲tzt und d칲rfen nicht ohne Erlaubnis in anderen Kontexten ver칬ffentlicht werden. Das gilt insbesondere f칲r Inhalte hinter Logins und personenbezogene Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c2567-7c8a-4d33-a9db-db45f08488a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
